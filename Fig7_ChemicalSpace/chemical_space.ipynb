{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f71b0d-c866-4edd-82bf-5727e378bbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc59ba7-e4ad-4205-98ef-a6295efcb148",
   "metadata": {},
   "source": [
    "# 1) User paths and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19e57e7-c9cf-4e3d-971f-a8e9df907966",
   "metadata": {},
   "source": [
    " a SMILES column in each table. For .smi files, the second token on each line (if present) is used as the molecule name; otherwise an auto name is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f08a71d-7a56-408a-93b4-b6e2dc30d903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change path\n",
    "MASTER_PATH = r\"/master_urease_dataset_unique2.xlsx\"\n",
    "OTHER1_PATH = r\"/Candidates.smi\"\n",
    "OTHER1_LABEL = \"Candidate Molecules\"\n",
    "OTHER2_PATH = r\"/Control.smi\"\n",
    "OTHER2_LABEL = \"Control Molecules\"\n",
    "MASTER_LABEL = \"Urease inhibitor set\"\n",
    "\n",
    "# List of (path, label) pairs used downstream for loading and labeling.\n",
    "\n",
    "DATASETS = [\n",
    "    (MASTER_PATH, MASTER_LABEL),\n",
    "    (OTHER1_PATH, OTHER1_LABEL),\n",
    "    (OTHER2_PATH, OTHER2_LABEL),\n",
    "]\n",
    "\n",
    "OUT_DIR = os.path.join(os.path.dirname(OTHER1_PATH), \"figures\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8741c4-f020-4867-abaf-a9f8bbdb0905",
   "metadata": {},
   "source": [
    "# 1.1 Safe Excel saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fc60fe-123b-4568-89cc-54760233adf0",
   "metadata": {},
   "source": [
    "save_excel_safe(): Robust writer that retries on PermissionError (e.g., file open in Excel) and switches writer engine if needed. It also timestamps the filename when collisions happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89aa3d14-98a3-4d02-a749-b633cd706bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_excel_safe(df: pd.DataFrame, path: str, tries: int = 3) -> str:\n",
    "    path = Path(path)\n",
    "    stem, suffix = path.stem, path.suffix or \".xlsx\"\n",
    "    for _ in range(tries):\n",
    "        try:\n",
    "            df.to_excel(path, index=False, engine=\"openpyxl\")\n",
    "            return str(path)\n",
    "        except PermissionError:\n",
    "            ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "            path = path.with_name(f\"{stem}_{ts}{suffix}\")\n",
    "            time.sleep(0.25)\n",
    "        except Exception:\n",
    "            try:\n",
    "                df.to_excel(path, index=False, engine=\"xlsxwriter\")\n",
    "                return str(path)\n",
    "            except PermissionError:\n",
    "                ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "                path = path.with_name(f\"{stem}_{ts}{suffix}\")\n",
    "                time.sleep(0.25)\n",
    "    df.to_excel(path, index=False, engine=\"openpyxl\")\n",
    "    return str(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7444de-9169-4d70-add8-ab2f70eb05c7",
   "metadata": {},
   "source": [
    "# 2) Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9f4a20-eff5-4523-b0af-74178d260bee",
   "metadata": {},
   "source": [
    "Utility functions to locate key columns, read CSVs robustly, normalize keys, and pick optional activity metadata when present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "260e7f03-197b-49fa-9ba1-6d73b4bfc323",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRA_COLS = [\"Activity_Type\", \"Value_nM\", \"Units\"]\n",
    "\n",
    "def _find_smiles_col(columns):\n",
    "    for c in columns:\n",
    "        if str(c).strip().lower() == \"smiles\":\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _find_name_col(columns):\n",
    "    candidates = [\n",
    "        \"name\", \"compound_id\", \"compound id\", \"molecule\", \"molecule_name\",\n",
    "        \"molecule name\", \"title\", \"preferred_name\", \"pert_iname\", \"drug_name\", \"id\"\n",
    "    ]\n",
    "    low = {str(c).strip().lower(): c for c in columns}\n",
    "    for k in candidates:\n",
    "        if k in low:\n",
    "            return low[k]\n",
    "    return None\n",
    "\n",
    "def _safe_read_csv(path):\n",
    "    try:\n",
    "        return pd.read_csv(path, sep=None, engine=\"python\")\n",
    "    except Exception:\n",
    "        return pd.read_csv(path)\n",
    "\n",
    "def _normalize_key(s: str) -> str:\n",
    "    return re.sub(r\"[\\s_]+\", \"\", str(s).strip().lower())\n",
    "\n",
    "def _pick_extra_cols(df: pd.DataFrame) -> dict:\n",
    "    std_keys = {c: _normalize_key(c) for c in EXTRA_COLS}\n",
    "    inv = {_normalize_key(c): c for c in df.columns}\n",
    "    out = {}\n",
    "    for std_name, std_key in std_keys.items():\n",
    "        candidates = [std_key]\n",
    "        if std_name == \"Activity_Type\":\n",
    "            candidates += [\"activitytype\"]\n",
    "        elif std_name == \"Value_nM\":\n",
    "            candidates += [\"valuenm\", \"value(nm)\", \"value_nm\"]\n",
    "        elif std_name == \"Units\":\n",
    "            candidates += [\"unit\", \"units\"]\n",
    "        for k in candidates:\n",
    "            if k in inv:\n",
    "                out[std_name] = inv[k]\n",
    "                break\n",
    "    return out\n",
    "\n",
    "def load_smiles_table(path):\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    base = os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "    def _ensure_name(df, base):\n",
    "        if \"Name\" not in df.columns:\n",
    "            df[\"Name\"] = [f\"{base}_{i+1:05d}\" for i in range(len(df))]\n",
    "        else:\n",
    "            df[\"Name\"] = df[\"Name\"].astype(str).str.strip().replace({\"\": None})\n",
    "            df[\"Name\"] = df[\"Name\"].fillna(pd.Series([f\"{base}_{i+1:05d}\" for i in range(len(df))], index=df.index))\n",
    "        return df\n",
    "\n",
    "    if ext in [\".xlsx\", \".xls\"]:\n",
    "        df = pd.read_excel(path)\n",
    "        col_smi = _find_smiles_col(df.columns)\n",
    "        if col_smi is None:\n",
    "            raise ValueError(f\"No 'SMILES' column found in: {path}\")\n",
    "        col_name = _find_name_col(df.columns)\n",
    "        keep = [col_smi] + ([col_name] if col_name else [])\n",
    "        extra_map = _pick_extra_cols(df)\n",
    "        for std in EXTRA_COLS:\n",
    "            if std in extra_map:\n",
    "                keep.append(extra_map[std])\n",
    "        df = df[keep].rename(columns={col_smi: \"SMILES\", (col_name or \"Name\"): \"Name\"})\n",
    "        if extra_map:\n",
    "            df = df.rename(columns={v: k for k, v in extra_map.items()})\n",
    "        df = _ensure_name(df, base)\n",
    "\n",
    "    elif ext in [\".csv\", \".tsv\"]:\n",
    "        df = _safe_read_csv(path)\n",
    "        col_smi = _find_smiles_col(df.columns)\n",
    "        if col_smi is None:\n",
    "            raise ValueError(f\"No 'SMILES' column found in: {path}\")\n",
    "        col_name = _find_name_col(df.columns)\n",
    "        keep = [col_smi] + ([col_name] if col_name else [])\n",
    "        extra_map = _pick_extra_cols(df)\n",
    "        for std in EXTRA_COLS:\n",
    "            if std in extra_map:\n",
    "                keep.append(extra_map[std])\n",
    "        df = df[keep].rename(columns={col_smi: \"SMILES\", (col_name or \"Name\"): \"Name\"})\n",
    "        if extra_map:\n",
    "            df = df.rename(columns={v: k for k, v in extra_map.items()})\n",
    "        df = _ensure_name(df, base)\n",
    "\n",
    "    elif ext == \".smi\":\n",
    "        smiles, names = [], []\n",
    "        with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "            for idx, line in enumerate(f, 1):\n",
    "                parts = line.strip().split()\n",
    "                if not parts:\n",
    "                    continue\n",
    "                smi = parts[0]\n",
    "                name = parts[1] if len(parts) > 1 else f\"{base}_{idx:05d}\"\n",
    "                smiles.append(smi)\n",
    "                names.append(name)\n",
    "        df = pd.DataFrame({\"SMILES\": smiles, \"Name\": names})\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file extension: {path}\")\n",
    "\n",
    "    df = df[df[\"SMILES\"].notna()].copy()\n",
    "    df[\"SMILES\"] = df[\"SMILES\"].astype(str).str.strip()\n",
    "    df = df[df[\"SMILES\"] != \"\"]\n",
    "    for c in EXTRA_COLS:\n",
    "        if c not in df.columns:\n",
    "            df[c] = pd.NA\n",
    "    return df[[\"SMILES\", \"Name\"] + EXTRA_COLS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d697510c-6c21-4d3c-89e4-32f02dfabb8a",
   "metadata": {},
   "source": [
    "# 3) Load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c386ed2f-e3f2-4f93-892a-00c7a31615ae",
   "metadata": {},
   "source": [
    " Read, deâ€‘duplicate by SMILES, and merge all datasets. Also prepare perâ€‘label SMILES sets for quick counts and overlap reasoning. Save the combined table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd9679-1627-4077-9137-af380a6c908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, sets_by_label = [], {}\n",
    "for path, label in DATASETS:\n",
    "    df = load_smiles_table(path)\n",
    "    df = df.drop_duplicates(subset=[\"SMILES\"]).reset_index(drop=True)\n",
    "    df[\"Label\"] = label\n",
    "    frames.append(df)\n",
    "    sets_by_label[label] = set(df[\"SMILES\"])\n",
    "\n",
    "df_all = pd.concat(frames, ignore_index=True)\n",
    "combined_xlsx = os.path.join(OUT_DIR, \"chemspace_combined_SMILES_labels.xlsx\")\n",
    "save_excel_safe(df_all, combined_xlsx)\n",
    "\n",
    "print(\"Summary per dataset:\")\n",
    "for label in sets_by_label:\n",
    "    print(f\"  - {label:<22}: {len(sets_by_label[label])} molecules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1324625e-aaf5-4a78-8f96-13d78ef26a4a",
   "metadata": {},
   "source": [
    "# 4) ChemPlot visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1908a8c-0f66-4370-b779-0e9d95ddcac6",
   "metadata": {},
   "source": [
    "Build a ChemPlot Plotter from SMILES + class labels. Choose the reducer (PCA/UMAP/tâ€‘SNE). Then export a static PNG and an interactive HTML plot.\n",
    "Postâ€‘process the static figure to tweak marker aesthetics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2747d815-44ec-4689-a253-a180fb67b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#~$ pip install chemplot\n",
    "from chemplot import Plotter\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "335f3095-6bdb-4918-a6cd-d53421f58847",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m REMOVE_OUTLIERS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m# optional outlier removal inside ChemPlot\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Create the Plotter with categorical targets given by dataset Label.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m cp \u001b[38;5;241m=\u001b[39m Plotter\u001b[38;5;241m.\u001b[39mfrom_smiles(\n\u001b[1;32m----> 7\u001b[0m df_all[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMILES\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[0;32m      8\u001b[0m target\u001b[38;5;241m=\u001b[39mdf_all[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[0;32m      9\u001b[0m target_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# 'C' = categorical targets\u001b[39;00m\n\u001b[0;32m     10\u001b[0m sim_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstructural\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# structural similarity (vs propertyâ€‘based)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Run the chosen dimensionality reducer.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m REDUCER\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mumap\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_all' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "REDUCER = \"umap\" # one of: 'pca', 'umap', 'tsne'\n",
    "REMOVE_OUTLIERS = False # optional outlier removal inside ChemPlot\n",
    "\n",
    "\n",
    "# Create the Plotter with categorical targets given by dataset Label.\n",
    "cp = Plotter.from_smiles(\n",
    "df_all[\"SMILES\"].tolist(),\n",
    "target=df_all[\"Label\"].tolist(),\n",
    "target_type=\"C\", # 'C' = categorical targets\n",
    "sim_type=\"structural\" # structural similarity (vs propertyâ€‘based)\n",
    ")\n",
    "\n",
    "\n",
    "# Run the chosen dimensionality reducer.\n",
    "if REDUCER.lower() == \"umap\":\n",
    "    cp.umap()\n",
    "elif REDUCER.lower() == \"tsne\":\n",
    "    cp.tsne()\n",
    "else:\n",
    "    cp.pca()\n",
    "\n",
    "labels = [label for _, label in DATASETS]\n",
    "suffix = REDUCER.upper()\n",
    "\n",
    "png_name = f\"chemspace_{'_vs_'.join(labels)}_{suffix}.png\"\n",
    "static_png = os.path.join(OUT_DIR, png_name)\n",
    "cp.visualize_plot(\n",
    "    kind=\"scatter\",\n",
    "    remove_outliers=REMOVE_OUTLIERS,\n",
    "    is_colored=True,\n",
    "    filename=static_png,\n",
    "    title=\"Chemical Space\"\n",
    ")\n",
    "print(f\" Static PNG saved â†’ {static_png}\")\n",
    "\n",
    "html_name = f\"chemspace_{'_vs_'.join(labels)}_{suffix}.html\"\n",
    "interactive_html = os.path.join(OUT_DIR, html_name)\n",
    "cp.interactive_plot(\n",
    "    kind=\"scatter\",\n",
    "    remove_outliers=REMOVE_OUTLIERS,\n",
    "    is_colored=True,\n",
    "    filename=interactive_html,\n",
    "    show_plot=False,\n",
    "    title=\"Chemical Space\"\n",
    ")\n",
    "print(f\"Interactive HTML saved â†’ {interactive_html}\")\n",
    "\n",
    "# --- Postâ€‘render: tweak marker edges/size/alpha on the static figure ---\n",
    "# ChemPlot generates a Matplotlib figure; we access it to adjust aesthetics\n",
    "# without reâ€‘drawing the embedding.\n",
    "fig = plt.gcf()\n",
    "ax = plt.gca()\n",
    "for coll in ax.collections:\n",
    "    coll.set_edgecolor(\"black\")\n",
    "    coll.set_linewidth(0.5)\n",
    "    coll.set_alpha(0.9)\n",
    "    coll.set_sizes([220])  # ðŸ”¹ tamaÃ±o de los cÃ­rculos aumentado\n",
    "fig.savefig(static_png, dpi=300, bbox_inches=\"tight\", facecolor=fig.get_facecolor())\n",
    "plt.close(fig)\n",
    "print(f\" PNG recolored and finalized â†’ {static_png}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3bfcb8-9922-4d50-8770-909582e265ab",
   "metadata": {},
   "source": [
    "# 5) Nearest neighbors in ChemPlot coordinates (TOPâ€‘K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd87b05c-bd82-4a62-84f9-9b2068f25d6b",
   "metadata": {},
   "source": [
    "For each candidate molecule (OTHER1_LABEL), compute Euclidean distance in the\n",
    "2D embedding to all molecules from other datasets, select topâ€‘K neighbors, and\n",
    "export a longâ€‘format table including activity fields when the neighbor belongs\n",
    "to the MASTER set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a875af8-0569-4309-9e87-7735fc3a2b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 5\n",
    "\n",
    "def _pick_xy_columns(df_plot: pd.DataFrame):\n",
    "    cols = {c.lower(): c for c in df_plot.columns}\n",
    "    for x_key, y_key in [\n",
    "        (\"x\", \"y\"),\n",
    "        (\"x1\", \"y1\"),\n",
    "        (\"pc1\", \"pc2\"),\n",
    "        (\"dim 1\", \"dim 2\"),\n",
    "        (\"dim1\", \"dim2\"),\n",
    "    ]:\n",
    "        if x_key in cols and y_key in cols:\n",
    "            return cols[x_key], cols[y_key]\n",
    "    num_cols = [c for c in df_plot.columns if np.issubdtype(df_plot[c].dtype, np.number)]\n",
    "    if len(num_cols) >= 2:\n",
    "        return num_cols[0], num_cols[1]\n",
    "    raise RuntimeError(\"Could not find X/Y columns in ChemPlot df_plot.\")\n",
    "\n",
    "def get_chemplot_coords_or_fallback(cp, df_all):\n",
    "    df_plot = getattr(cp, \"df_plot\", None)\n",
    "    if isinstance(df_plot, pd.DataFrame) and len(df_plot) == len(df_all):\n",
    "        xcol, ycol = _pick_xy_columns(df_plot)\n",
    "        coords_df = df_all[[\"SMILES\", \"Name\", \"Label\"] + EXTRA_COLS].copy()\n",
    "        coords_df[\"X\"] = df_plot[xcol].to_numpy()\n",
    "        coords_df[\"Y\"] = df_plot[ycol].to_numpy()\n",
    "        return coords_df\n",
    "\n",
    "    print(\"Could not read 2D coords from ChemPlot; using PCA over ECFP4 as fallback.\")\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import AllChem\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    def mol_from_smiles(s):\n",
    "        try:\n",
    "            return Chem.MolFromSmiles(s)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    N_BITS = 2048\n",
    "    df_tmp = df_all.copy()\n",
    "    df_tmp[\"Mol\"] = df_tmp[\"SMILES\"].apply(mol_from_smiles)\n",
    "    df_tmp = df_tmp[df_tmp[\"Mol\"].notna()].copy()\n",
    "    df_tmp[\"FP\"] = df_tmp[\"Mol\"].apply(lambda m: AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=N_BITS))\n",
    "    X = np.vstack([np.array(fp.ToList(), dtype=np.int8) for fp in df_tmp[\"FP\"]])\n",
    "    coords = PCA(n_components=2, random_state=42).fit_transform(X)\n",
    "\n",
    "    coords_df = df_tmp[[\"SMILES\", \"Name\", \"Label\"] + EXTRA_COLS].copy()\n",
    "    coords_df[\"X\"] = coords[:, 0]\n",
    "    coords_df[\"Y\"] = coords[:, 1]\n",
    "    return coords_df\n",
    "\n",
    "coords_df = get_chemplot_coords_or_fallback(cp, df_all).reset_index(drop=True)\n",
    "queries = coords_df[coords_df[\"Label\"] == OTHER1_LABEL].copy()\n",
    "pool = coords_df[coords_df[\"Label\"] != OTHER1_LABEL].copy()\n",
    "\n",
    "rows_long = []\n",
    "for _, q in queries.iterrows():\n",
    "    dx = pool[\"X\"].to_numpy() - q[\"X\"]\n",
    "    dy = pool[\"Y\"].to_numpy() - q[\"Y\"]\n",
    "    dist = np.sqrt(dx * dx + dy * dy)\n",
    "    k = min(TOP_K, np.isfinite(dist).sum())\n",
    "    idx = np.argpartition(dist, k)[:k]\n",
    "    idx = idx[np.argsort(dist[idx])]\n",
    "    for rank, i in enumerate(idx, start=1):\n",
    "        nn = pool.iloc[i]\n",
    "        row = {\n",
    "            \"Query_Name\": q[\"Name\"],\n",
    "            \"Query_SMILES\": q[\"SMILES\"],\n",
    "            \"NN_Rank\": rank,\n",
    "            \"Neighbor_Name\": nn[\"Name\"],\n",
    "            \"Neighbor_SMILES\": nn[\"SMILES\"],\n",
    "            \"Neighbor_Origin\": nn[\"Label\"],\n",
    "            \"Dist2D\": float(dist[i]),\n",
    "        }\n",
    "        if nn[\"Label\"] == MASTER_LABEL:\n",
    "            row[\"NN_Activity_Type\"] = nn.get(\"Activity_Type\", pd.NA)\n",
    "            row[\"NN_Value_nM\"] = nn.get(\"Value_nM\", pd.NA)\n",
    "            row[\"NN_Units\"] = nn.get(\"Units\", pd.NA)\n",
    "        else:\n",
    "            row[\"NN_Activity_Type\"] = pd.NA\n",
    "            row[\"NN_Value_nM\"] = pd.NA\n",
    "            row[\"NN_Units\"] = pd.NA\n",
    "        rows_long.append(row)\n",
    "\n",
    "nn_long_df = pd.DataFrame(rows_long)\n",
    "safe_label = OTHER1_LABEL.replace(\" \", \"_\")\n",
    "nn_long_xlsx = os.path.join(OUT_DIR, f\"nearest_neighbors_top{TOP_K}_long_{safe_label}_{suffix}_2D.xlsx\")\n",
    "nn_long_xlsx = save_excel_safe(nn_long_df, nn_long_xlsx)\n",
    "\n",
    "print(f\"\\nSaved NN (long, ChemPlot 2D): {nn_long_xlsx}\")\n",
    "print(f\"   Candidates: {len(queries)} | Rows NN: {len(nn_long_df)} \"\n",
    "      f\"(expected â‰ˆ {len(queries)*TOP_K} if there is enough pool)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
